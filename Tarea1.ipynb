{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf044b72-0aa3-4eb8-ae50-fc9215cd9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3bd9ab-2089-488c-93c6-1ae4fad15e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['SalePrice' 'OverallQual' '1stFlrSF' 'TotRmsAbvGrd' 'YearBuilt'\n",
      "  'LotFrontage']\n",
      " ['208500.0' '7.0' '856.0' '8.0' '2003.0' '65.0']\n",
      " ['181500.0' '6.0' '1262.0' '6.0' '1976.0' '80.0']\n",
      " ...\n",
      " ['266500.0' '7.0' '1188.0' '9.0' '1941.0' '66.0']\n",
      " ['142125.0' '5.0' '1078.0' '5.0' '1950.0' '68.0']\n",
      " ['147500.0' '5.0' '1256.0' '6.0' '1965.0' '75.0']]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(\"proyecto_training_data.npy\")\n",
    "dataset = dataset[~np.isnan(dataset).any(axis=1), :] #Dataset contiene nans, los ignoro en la implementacion\n",
    "fields = [\"SalePrice\", \"OverallQual\", \"1stFlrSF\", \"TotRmsAbvGrd\", \"YearBuilt\", \"LotFrontage\"]\n",
    "print(np.vstack((np.array(fields), dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6645cc-cb4a-43c9-bb83-c71f8f66f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:\n",
    "    def __init__(self, batch_size = 16, lr=0.01, epochs = 1000):\n",
    "        self.logdir = f'logs\\\\lm_bs={batch_size}_lr={lr}_epochs={epochs}_bs={batch_size}'\n",
    "        self.writer = tf.summary.create_file_writer(self.logdir)\n",
    "        self.m = tf.Variable(initial_value=0.0, name=\"slope\")\n",
    "        self.b = tf.Variable(initial_value=0.0, name=\"intercept\")\n",
    "        tf.summary.trace_on(graph=True, profiler=False)\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "        self.lr = lr \n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def h(self, m, b, x):\n",
    "        y = tf.cast(m, tf.float64)*tf.cast(x, tf.float64) + tf.cast(b, tf.float64)\n",
    "        return y\n",
    "    \n",
    "    def get_params(self):\n",
    "        return((self.m, self.b))\n",
    "    \n",
    "    def error(self, y,y_pred):\n",
    "        return 1/2*tf.reduce_mean(tf.math.square(y - y_pred), name=\"MSE_Calc\")\n",
    "\n",
    "    def __call__(self,x):\n",
    "        return self.h(self.m, self.b, x)\n",
    "    \n",
    "    @tf.function\n",
    "    def train(self, x, y):\n",
    "        batch_size = self.batch_size\n",
    "        lr = self.lr \n",
    "        epochs = self.epochs\n",
    "        \n",
    "        iterations = int(len(y)/batch_size)\n",
    "        step = 0\n",
    "        with self.writer.as_default():\n",
    "            for epoch in range(epochs):\n",
    "                for i in range(iterations): \n",
    "                    batch_start = i*batch_size\n",
    "                    batch_end = batch_start + batch_size\n",
    "                    x_mb = tf.reshape(x[batch_start:batch_end], [-1,1])\n",
    "                    y_mb = tf.reshape(y[batch_start:batch_end], [-1,1])\n",
    "                        \n",
    "                        \n",
    "                    with tf.GradientTape() as grad_tape:\n",
    "                        grad_tape.watch(self.b)\n",
    "                        grad_tape.watch(self.m)\n",
    "\n",
    "                        y_pred = self.h(self.m, self.b, x_mb)\n",
    "\n",
    "                        error = self.error(y_mb, y_pred)\n",
    "\n",
    "                    # calcular el gradiente de la funcion de costo respecto de los parametros\n",
    "                    grad_m,grad_b = grad_tape.gradient(error,[self.m, self.b])\n",
    "\n",
    "                    # actualizar los parametros dando un paso en direccion contraria al gradiente\n",
    "                    self.m.assign(self.m - lr*grad_m)\n",
    "                    self.b.assign(self.b - lr*grad_b)\n",
    "                    tf.summary.scalar('MSE', error, step=step)\n",
    "                    step += 1\n",
    "        final_params = (self.m, self.b)\n",
    "        #self.writer.flush()\n",
    "\n",
    "        return final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2bef79-3af8-469d-8da2-e2861a044fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trace already enabled\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.create_file_writer(\"logs\\\\modelgraph\")\n",
    "model1 = LinearModel(epochs = 50, lr = 0.0001, batch_size=200)\n",
    "tf.summary.trace_on(graph=True)\n",
    "model1.train(dataset[:,1], dataset[:,0])\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "                                  name=\"my_func_trace\",\n",
    "                                  step=0,\n",
    "                                  profiler_outdir=\"logs\\\\modelgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af9e964-a4dd-4a0d-b980-fddf6c1a6fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(23987.783203125, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(model1(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14e79da-4029-4dae-892e-3c008e46ec5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'slope:0' shape=() dtype=float32, numpy=20914.29>,\n",
       " <tf.Variable 'intercept:0' shape=() dtype=float32, numpy=3073.4941>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a73a35-51e9-48ee-abd2-3e98566c13e7",
   "metadata": {},
   "source": [
    "# Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e3f00-bf64-41f5-a8e3-c430b08f865e",
   "metadata": {},
   "source": [
    "Hipotesis: Un LR alto causara una reduccion de error mas rapidamente pero causara divergencia mas tardia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1001ac7e-a7e5-44f5-9868-b000c72e211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:Trace already enabled\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "lrs = [0.1, 0.01, 0.001]\n",
    "epochs = [100, 1000]\n",
    "batch_sizes = [100, 500]\n",
    "\n",
    "for lr, epoch, batch_size in list(itertools.product(lrs, epochs, batch_sizes)):\n",
    "    model = LinearModel(epochs = epoch, lr = lr, batch_size = batch_size)\n",
    "    model.train(dataset[:,1], dataset[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75370370-1eda-437f-8307-7a83b7005bb8",
   "metadata": {},
   "source": [
    "![alt text](MSEs.png \"MSEs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776992b2-c9d6-478d-9cd3-87a4d8778f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "El error tiende a ser mas bajo cuando Batch Size = 100, lr+0.001, e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
